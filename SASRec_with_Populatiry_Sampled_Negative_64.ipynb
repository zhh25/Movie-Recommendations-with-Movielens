{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "toc_visible": true,
      "mount_file_id": "1Ro4BiyReprzswlpNxHEMnJ3ocQGzhcWM",
      "authorship_tag": "ABX9TyNLmNNWIuoRdGyS4FBt2Zcy"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install -q tensorflow-recommenders"
      ],
      "metadata": {
        "id": "UYJf1mywtVhW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97f7c99d-21ba-4494-f84f-609d01eacee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/96.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5qTF8A_aijm"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/MyDrive/Movie Recommendations with Movielens/data/'"
      ],
      "metadata": {
        "id": "YizoJ-KvW6wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 50\n",
        "batch_size = 4096\n",
        "embedding_dimension = 64\n",
        "\n",
        "num_heads = 1\n",
        "ffn_hidden_unit = 64\n",
        "dropout = 0.5\n",
        "use_causal_mask = False\n",
        "blocks = 2\n",
        "learning_rate = 0.001\n",
        "epoch = 100\n",
        "\n",
        "negative_example = 100\n"
      ],
      "metadata": {
        "id": "qaSHOMG4yfn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, I impliment the model proposed in paper [Self-Attentive Sequential Recommendaiton](https://arxiv.org/pdf/1808.09781.pdf).\n",
        "\n",
        "The dataset is collected from the movie-recommendation service MovieLens. Created by 138,493 users, the Movielens data set includes over 20 million ratings and 460,000+ tags for 27,278 movies.\n",
        "\n",
        "Kaggle data set: [MovieLens 20M Dataset](https://www.kaggle.com/datasets/grouplens/movielens-20m-dataset?resource=download)"
      ],
      "metadata": {
        "id": "HTRZ0HtCua_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 1. Data Preprocess\n"
      ],
      "metadata": {
        "id": "e8zwsOMS1UG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Filter\n",
        "I only include movies with at least 5 ratings(watchs). And I only include recodes with rating >= 2, in other words, only include watch history that the user enjoy.\n",
        "\n",
        "We end up with about 18M records."
      ],
      "metadata": {
        "id": "IEGsCpr3iToE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = pd.read_csv('/content/drive/MyDrive/Movie Recommendations with Movielens/data/rating.csv',\n",
        "                      #usecols = ['userId', 'movieId', 'timestamp'],\n",
        "                      #dtype = {'movieId': str, 'userId': str},\n",
        "                      #nrows = 1000000\n",
        "                    )"
      ],
      "metadata": {
        "id": "kB_kyJP81cfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PyIF0uCK10nZ",
        "outputId": "f01aae2c-d174-4259-b0f3-ad82946380a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  movieId  rating            timestamp\n",
              "0       1        2     3.5  2005-04-02 23:53:47\n",
              "1       1       29     3.5  2005-04-02 23:31:16\n",
              "2       1       32     3.5  2005-04-02 23:33:39\n",
              "3       1       47     3.5  2005-04-02 23:32:07\n",
              "4       1       50     3.5  2005-04-02 23:29:40"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcf2832f-d1b5-4abd-921e-e3b4fd29b0ad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:53:47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:31:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:33:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:32:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:29:40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcf2832f-d1b5-4abd-921e-e3b4fd29b0ad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fcf2832f-d1b5-4abd-921e-e3b4fd29b0ad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fcf2832f-d1b5-4abd-921e-e3b4fd29b0ad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings['movie_count'] = ratings.groupby('movieId')['movieId'].transform('count')\n",
        "#\n",
        "ratings = ratings[ratings.movie_count >= 5]\n",
        "# only include recodes with rating >= 2\n",
        "# in other words, only include watch history that the user enjoy\n",
        "ratings = ratings[ratings.rating >= 2]\n",
        "ratings = ratings.sort_values(by=['userId', 'timestamp'])"
      ],
      "metadata": {
        "id": "NCRuIENx2BdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZyMXx4UFth-",
        "outputId": "c85025b9-2f1a-4463-8463-983f80b66db6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 18786848 entries, 20 to 19999916\n",
            "Data columns (total 5 columns):\n",
            " #   Column       Dtype  \n",
            "---  ------       -----  \n",
            " 0   userId       int64  \n",
            " 1   movieId      int64  \n",
            " 2   rating       float64\n",
            " 3   timestamp    object \n",
            " 4   movie_count  int64  \n",
            "dtypes: float64(1), int64(3), object(1)\n",
            "memory usage: 860.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#folder_path = \"/content/drive/MyDrive/Movie Recommendations with Movielens/\"\n",
        "ratings.to_csv(folder_path + 'rating_filtered.csv', index = False)"
      ],
      "metadata": {
        "id": "z0aS6c9XZ7Ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Train and Test Split\n",
        "We split the historical sequence for each user in to three parts:\n",
        "1.   the most recent action for testing\n",
        "2.   the second most recent action fro validation\n",
        "3.   all remaining actions for training\n",
        "\n"
      ],
      "metadata": {
        "id": "1FJmU3RmGbCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#folder_path = \"/content/drive/MyDrive/Movie Recommendations with Movielens/\"\n",
        "ratings = pd.read_csv(folder_path + 'rating_filtered.csv',\n",
        "                      usecols = ['userId', 'movieId'],\n",
        "                      dtype = {'movieId': str, 'userId': str},\n",
        "                      )"
      ],
      "metadata": {
        "id": "Uld3ZRZhb8tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data, test_data = defaultdict(list), defaultdict(list), defaultdict(list)"
      ],
      "metadata": {
        "id": "ZfHFgWKG8iGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for userId, df in tqdm(ratings[['userId', 'movieId']].groupby('userId')):\n",
        "    pos_list = df['movieId'].tolist()\n",
        "\n",
        "    for i in range(1, len(pos_list)):\n",
        "        hist_i = pos_list[max(0,i-maxlen):i]\n",
        "        if i == len(pos_list) - 1:\n",
        "            test_data['hist'].append(hist_i)\n",
        "            test_data['pos_id'].append(pos_list[i])\n",
        "        elif i == len(pos_list) - 2:\n",
        "            val_data['hist'].append(hist_i)\n",
        "            val_data['pos_id'].append(pos_list[i])\n",
        "        else:\n",
        "        #if i < len(pos_list) - 2:\n",
        "            train_data['hist'].append(hist_i)\n",
        "            train_data['pos_id'].append(pos_list[i])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5faepv387-V",
        "outputId": "43bd6e36-9d2b-40e6-cd25-96114cac0a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 138469/138469 [01:23<00:00, 1659.09it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data['hist'][0:5])\n",
        "print(train_data['pos_id'][:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WMbXbFgCY_o",
        "outputId": "c30fe008-53e9-483b-e169-fe6ec5bbb696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['924'], ['924', '919'], ['924', '919', '2683'], ['924', '919', '2683', '1584'], ['924', '919', '2683', '1584', '1079']]\n",
            "['919', '2683', '1584', '1079', '653']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame(test_data)\n",
        "test_df['hist'] = test_df['hist'].apply(lambda x: ','.join([id for id in x]))\n",
        "test_df.to_csv(folder_path + 'test_SASRec.csv', index = False, sep='|' )\n"
      ],
      "metadata": {
        "id": "VKqnghhUigvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df = pd.DataFrame(val_data)\n",
        "val_df['hist'] = val_df['hist'].apply(lambda x: ','.join([id for id in x]))\n",
        "val_df.to_csv(folder_path + 'val_SASRec.csv', index = False, sep='|' )"
      ],
      "metadata": {
        "id": "80A7f-uBjTWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame(train_data)\n",
        "train_df['hist'] = train_df['hist'].apply(lambda x: ','.join([id for id in x]))\n",
        "train_df.to_csv(folder_path + 'train_SASRec.csv', index = False, sep='|' )"
      ],
      "metadata": {
        "id": "J0PHemql0esi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load Preprcessed Data"
      ],
      "metadata": {
        "id": "4BX1eTXxL2EQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Create tf.data.Dataset for training and evaluation"
      ],
      "metadata": {
        "id": "PFX-1b-JH1W2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to put padding before each row (rather than after), then you can't currently do that with RaggedTensor.to_tensor. But you can write a fairly [simple function](https://github.com/tensorflow/tensorflow/issues/34793) to do it:\n"
      ],
      "metadata": {
        "id": "3FF30NsJ0EkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_from_csv(csv_file_path, shuffle=False, batch_size=batch_size, maxlen = maxlen):\n",
        "\n",
        "    def left_pad_2d_ragged(rt, width = maxlen):\n",
        "        #rt = rt[-width:]  # Truncate rows to have at most `width` items\n",
        "        pad_row_lengths = width - rt.row_lengths()\n",
        "        pad_values = tf.zeros([(width * rt.nrows()) - tf.size(rt, tf.int64)], rt.dtype)\n",
        "        padding = tf.RaggedTensor.from_row_lengths(pad_values, pad_row_lengths)\n",
        "        return tf.concat([padding, rt], axis=1).to_tensor()\n",
        "\n",
        "    def process(features):\n",
        "        features[\"hist\"] = tf.strings.split(features[\"hist\"], \",\")#.to_tensor(shape = [None, maxlen])\n",
        "        features['hist'] = left_pad_2d_ragged(features['hist'], width = maxlen)\n",
        "\n",
        "        return features\n",
        "\n",
        "\n",
        "    dataset = tf.data.experimental.make_csv_dataset(\n",
        "        csv_file_path,\n",
        "        batch_size=batch_size,\n",
        "        num_epochs=1,\n",
        "        header=True,\n",
        "        field_delim=\"|\",\n",
        "        shuffle=shuffle,\n",
        "        column_defaults = ['string', 'string'],\n",
        "        shuffle_buffer_size=100*batch_size\n",
        "    ).map(process)\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "XW3XvHtNH5Fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = get_dataset_from_csv(folder_path + 'train_SASRec.csv',\n",
        "                                     shuffle=True, batch_size=batch_size)\n",
        "val_dataset = get_dataset_from_csv(folder_path + 'val_SASRec.csv',\n",
        "                                     shuffle=True, batch_size=negative_example +1)\n",
        "test_dataset = get_dataset_from_csv(folder_path + 'test_SASRec.csv',\n",
        "                                     shuffle=True, batch_size=negative_example +1)\n",
        "#drop the last batch\n",
        "#train_dataset = train_dataset.rebatch(batch_size, drop_remainder=True)\n",
        "#val_dataset = val_dataset.rebatch(negative_example +1, drop_remainder=True)\n",
        "#test_dataset = test_dataset.rebatch(negative_example +1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "oUe7KqP0K2RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "for sample_data in train_dataset.take(1):#.as_numpy_iterator():\n",
        "    break\n",
        "for sample_val in val_dataset.take(1):#.as_numpy_iterator():\n",
        "    break\n",
        "print(sample_data['hist'].shape)\n",
        "print(sample_data['pos_id'].shape)\n",
        "\n",
        "print(sample_val['hist'].shape)\n",
        "print(sample_val['pos_id'].shape)\n",
        "\n",
        "sample_data['hist']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZTIftfHN6iF",
        "outputId": "1841dec0-e760-4a56-8ed9-025f040046ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4096, 50)\n",
            "(4096,)\n",
            "(101, 50)\n",
            "(101,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4096, 50), dtype=string, numpy=\n",
              "array([[b'61132', b'102716', b'2193', ..., b'1377', b'3897', b'3793'],\n",
              "       [b'8371', b'33162', b'2231', ..., b'6281', b'1385', b'5065'],\n",
              "       [b'4432', b'1945', b'2612', ..., b'1080', b'1261', b'3424'],\n",
              "       ...,\n",
              "       [b'1717', b'2717', b'2420', ..., b'4974', b'3440', b'3821'],\n",
              "       [b'', b'', b'', ..., b'2028', b'4022', b'5989'],\n",
              "       [b'4975', b'1587', b'39', ..., b'3263', b'2269', b'8376']],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# choose a row which is padded on the left\n",
        "# use this row to check remaining functions\n",
        "id = 0"
      ],
      "metadata": {
        "id": "7koNahaEwxne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. MovieId Vocabulary"
      ],
      "metadata": {
        "id": "wg85PQkJOMsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies = pd.read_csv(\n",
        "    folder_path + 'movie.csv',\n",
        "    dtype = {'movieId': str},\n",
        "    usecols = ['movieId'],\n",
        ")\n",
        "\n",
        "movieId_vocab =  list(movies.movieId.unique())"
      ],
      "metadata": {
        "id": "KyQgpWXdOBBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Query Model"
      ],
      "metadata": {
        "id": "WyFNa_tA1Ru4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential, layers, callbacks, utils"
      ],
      "metadata": {
        "id": "dwgDfcDH5G4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.1 Embedding and positional embedding layer\n",
        "we will use the same movies Id lookup and embedding layers in both query model and item model."
      ],
      "metadata": {
        "id": "Zbp75wKL8j8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movieId_lookup = layers.StringLookup(\n",
        "    vocabulary = movieId_vocab,\n",
        "    )\n",
        "\n",
        "# about masking https://www.tensorflow.org/guide/keras/masking_and_padding\n",
        "movieId_embedding = layers.Embedding(\n",
        "    input_dim = len(movieId_vocab) + 1,\n",
        "    output_dim = embedding_dimension,\n",
        "    mask_zero = True,\n",
        ")"
      ],
      "metadata": {
        "id": "eBaJzLz5QdsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "movieId_lookup(sample_data['hist'])\n",
        "movieId_lookup(sample_val['hist'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X433n5Sahbc",
        "outputId": "96195562-cf2f-4666-a3f3-e440da00ffc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(101, 50), dtype=int64, numpy=\n",
              "array([[22918, 18741, 13917, ..., 18035, 17507, 22582],\n",
              "       [ 3670,  1778,   897, ...,   892,  3461,  2516],\n",
              "       [ 1874,  1878,  2111, ...,  2614,   365,   374],\n",
              "       ...,\n",
              "       [    0,     0,     0, ...,   346,   587,   377],\n",
              "       [    0,     0,     0, ...,   588,   538,  7250],\n",
              "       [    0,     0,     0, ...,  2643,  3264,  4170]])>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, movieId_lookup, movieId_embedding, maxlen, embedding_dimension):\n",
        "        super().__init__()\n",
        "        self.maxlen = maxlen\n",
        "        self.movieId_lookup = movieId_lookup\n",
        "        self.movieId_embedding = movieId_embedding\n",
        "        self.pos_embedding = layers.Embedding(input_dim = maxlen, output_dim = embedding_dimension)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.movieId_lookup(x)\n",
        "        x = self.movieId_embedding(x)\n",
        "        mask = x._keras_mask\n",
        "        mask1 = tf.expand_dims(mask, axis = 2) # [:, :, None]\n",
        "        mask2 = tf.expand_dims(mask, axis = 1) # [:, None, :]\n",
        "        attention_mask = mask1 & mask2 #[:,:,:]\n",
        "        mask = tf.expand_dims(tf.cast(mask, tf.float32), axis = -1)\n",
        "        x = x + tf.expand_dims(self.pos_embedding(tf.range(self.maxlen)), axis = 0)\n",
        "        #x = x * mask\n",
        "        return x, mask, attention_mask"
      ],
      "metadata": {
        "id": "LieBNqi47fH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test the above function\n",
        "embed_hist, mask, attention_mask = PositionalEmbedding(movieId_lookup, movieId_embedding, maxlen, embedding_dimension)(sample_data['hist'])\n",
        "embed_hist_val, mask_val, attention_mask_val = PositionalEmbedding(movieId_lookup, movieId_embedding, maxlen, embedding_dimension)(sample_val['hist'])\n",
        "print(embed_hist.shape)\n",
        "\n",
        "print(mask.shape)\n",
        "\n",
        "print(attention_mask.shape)\n",
        "attention_mask[id]\n",
        "#embed_hist * mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ61rDOsD488",
        "outputId": "96efe46e-70a1-4dee-8fd3-ae99c5143e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4096, 50, 64)\n",
            "(4096, 50, 1)\n",
            "(4096, 50, 50)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50, 50), dtype=bool, numpy=\n",
              "array([[ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       ...,\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True]])>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2 Attention block"
      ],
      "metadata": {
        "id": "oUvTyaWvq8RB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_heads, embedding_dimension, dropout):\n",
        "        super().__init__()\n",
        "        self.mha = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dimension)\n",
        "        self.layernorm = layers.LayerNormalization()\n",
        "        self.add = layers.Add()\n",
        "        self.dropout = layers.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def call(self, x, attention_mask):\n",
        "        att = self.mha(query = x, value = x, attention_mask = attention_mask)\n",
        "        att = self.dropout(att)\n",
        "        att = self.add([x, att])\n",
        "        att = self.layernorm(att)\n",
        "        return att"
      ],
      "metadata": {
        "id": "U1IvFOUTqvkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test the above function\n",
        "att = AttentionBlock(num_heads, embedding_dimension, dropout)(embed_hist * mask, attention_mask )\n",
        "att[id,:,0]\n",
        "AttentionBlock(num_heads, embedding_dimension, dropout)(embed_hist_val * mask_val, attention_mask_val ).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krvfFj9w1Qz6",
        "outputId": "0eb2125a-64c6-49fc-ca8f-b81128e0a862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([101, 50, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.3 Feed Forward block"
      ],
      "metadata": {
        "id": "gPRHKqO1wu5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "    def __init__(self, ffn_hidden_unit, embedding_dimension, dropout):\n",
        "        super().__init__()\n",
        "        self.seq = Sequential([\n",
        "            layers.Dense(ffn_hidden_unit, activation = 'relu'),\n",
        "            layers.Dense(embedding_dimension),\n",
        "            layers.Dropout(dropout)\n",
        "        ])\n",
        "        self.add = layers.Add()\n",
        "        self.layernorm = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.add([x, self.seq(x)])\n",
        "        x = self.layernorm(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "POcZHWk5IC5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test the above function\n",
        "ff = FeedForward(ffn_hidden_unit, embedding_dimension, dropout)(att)\n",
        "print(ff.shape)\n",
        "ff[id,:,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0n5oiXg6tay",
        "outputId": "f6b8eebf-bac4-46e8-d946-15d29690c786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4096, 50, 64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
              "array([-1.6552001 ,  1.4077022 , -1.4846429 ,  0.36595032,  0.37804344,\n",
              "       -1.712226  ,  0.14214924,  0.3816294 ,  0.3750532 , -1.1381018 ,\n",
              "        1.7527851 , -0.52342856, -0.55472463,  0.688848  , -2.1020875 ,\n",
              "       -1.7041838 , -0.8114975 , -1.6758058 ,  1.5546358 , -0.78213733,\n",
              "       -0.43383166,  1.2408466 , -0.41690263, -0.3560957 , -1.1664238 ,\n",
              "        0.0383225 ,  0.55275244,  0.61813945,  0.5143788 , -1.4343904 ,\n",
              "        0.51297015, -1.2772094 , -0.49824008, -0.7967505 , -0.09998196,\n",
              "       -0.898908  , -0.08261719, -0.86967444,  0.6260975 , -2.2544744 ,\n",
              "       -0.04179642, -0.7617358 , -0.91603804, -0.49991947, -0.6970702 ,\n",
              "       -0.38423356, -1.0491843 ,  0.05154865, -2.5700066 ,  0.5543088 ],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.4 Query Model"
      ],
      "metadata": {
        "id": "qCxdWx-75XtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QueryModel(tf.keras.Model):\n",
        "    def __init__(self, blocks, movieId_lookup, movieId_embedding, maxlen, embedding_dimension,\n",
        "                 num_heads, dropout, ffn_hidden_unit ):\n",
        "        super().__init__()\n",
        "        self.pos_embedding = PositionalEmbedding(movieId_lookup, movieId_embedding,\n",
        "                                                 maxlen, embedding_dimension)\n",
        "        self.attention_blocks = [AttentionBlock(num_heads, embedding_dimension,\n",
        "                                                dropout) for i in range(blocks)]\n",
        "        self.ff_blocks = [FeedForward(ffn_hidden_unit, embedding_dimension, dropout) for i in range(blocks)]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        emb, mask, attention_mask = self.pos_embedding(inputs['hist'])\n",
        "        h = emb * mask\n",
        "        for attention_block, ff_block in zip(self.attention_blocks, self.ff_blocks):\n",
        "            h = attention_block(h, attention_mask)\n",
        "            h = ff_block(h)\n",
        "        return h[:,-1, :]\n"
      ],
      "metadata": {
        "id": "rOB_aVpr2dyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test the above function\n",
        "output = QueryModel(blocks,movieId_lookup, movieId_embedding,\n",
        "           maxlen, embedding_dimension,num_heads,dropout,ffn_hidden_unit)(sample_data)\n",
        "print(output.shape)\n",
        "\n",
        "output_val = QueryModel(blocks,movieId_lookup, movieId_embedding,\n",
        "           maxlen, embedding_dimension,num_heads,dropout,ffn_hidden_unit)(sample_val)\n",
        "output_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMBinmt6ASA7",
        "outputId": "c528afcb-21f4-456a-b5e5-c6a5599af6bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4096, 64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([101, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Candidate Model"
      ],
      "metadata": {
        "id": "TYVWgimhBcRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CandidateModel(tf.keras.Model):\n",
        "    def __init__(self, movieId_lookup, movieId_embedding):\n",
        "        super().__init__()\n",
        "        self.movieId_lookup = movieId_lookup\n",
        "        self.movieId_embedding = movieId_embedding\n",
        "\n",
        "    def call(self,inputs):\n",
        "        lk = self.movieId_lookup(inputs['pos_id'])\n",
        "        emb = self.movieId_embedding(lk)\n",
        "        return emb"
      ],
      "metadata": {
        "id": "5hcEVeryBVRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test the above function\n",
        "print(CandidateModel(movieId_lookup, movieId_embedding)(sample_data).shape)\n",
        "print(CandidateModel(movieId_lookup, movieId_embedding)(sample_val).shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB0o9tFXDSGe",
        "outputId": "fcf3ef97-8cf7-4660-e26c-95b99d2ad5a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4096, 64)\n",
            "(101, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Full Model"
      ],
      "metadata": {
        "id": "daKxorenDwGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_ds = tf.data.Dataset.from_tensor_slices({'pos_id': movies.movieId})\n",
        "\n",
        "candidate_model = CandidateModel(movieId_lookup, movieId_embedding)\n",
        "movies_ds.batch(128).map(candidate_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu7KycTmAhUN",
        "outputId": "b39490f4-2213-4126-d1f1-245f3562d53e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionModel(tfrs.models.Model):\n",
        "\n",
        "    def __init__(self, blocks, movieId_lookup, movieId_embedding, maxlen, embedding_dimension,\n",
        "                 num_heads, dropout, ffn_hidden_unit):\n",
        "        super().__init__()\n",
        "        self.query_model = QueryModel(blocks,movieId_lookup, movieId_embedding,\n",
        "                                      maxlen, embedding_dimension,num_heads,dropout,ffn_hidden_unit)\n",
        "        self.candidate_model = CandidateModel(movieId_lookup, movieId_embedding)\n",
        "        self.task = tfrs.tasks.Retrieval(\n",
        "            loss = tf.keras.losses.CategoricalCrossentropy(\n",
        "                from_logits = True,\n",
        "                reduction = tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE),\n",
        "            #metrics = tfrs.metrics.FactorizedTopK(\n",
        "            #    candidates = movies_ds.batch(128).map(self.candidate_model)),\n",
        "            batch_metrics=[tf.keras.metrics.TopKCategoricalAccuracy(k=10, name = 'batch_top_10_categorical_accuracy')],\n",
        "            #remove_accidental_hits = True,\n",
        "            #num_hard_negatives=100,\n",
        "        )\n",
        "\n",
        "    def compute_loss(self, inputs, training: bool = False):\n",
        "        query_emb = self.query_model(inputs)\n",
        "        movie_emb = self.candidate_model(inputs)\n",
        "        #candidate_ids = inputs['pos_id']\n",
        "        return self.task(query_emb, movie_emb,\n",
        "                         compute_metrics = not training,\n",
        "                         compute_batch_metrics = True,\n",
        "                         #candidate_ids = candidate_ids\n",
        "                         )\n"
      ],
      "metadata": {
        "id": "zIxyTXIhEhgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AttentionModel(blocks, movieId_lookup, movieId_embedding, maxlen, embedding_dimension,\n",
        "                 num_heads, dropout, ffn_hidden_unit)\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate))"
      ],
      "metadata": {
        "id": "8_q5_jlxCHwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test full model\n",
        "print(model.compute_loss(sample_data))\n",
        "print(model.compute_loss(sample_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViybYlZAE2hN",
        "outputId": "fb364166-bfbf-4be7-edfb-2a20d9188997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(8.343054, shape=(), dtype=float32)\n",
            "tf.Tensor(4.6482296, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Fitting and evaluating"
      ],
      "metadata": {
        "id": "ceQkZ-tEB_iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefetch_train = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "prefetch_val = val_dataset.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "vg_RctE1rzBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_filepath = '/content/drive/MyDrive/Movie Recommendations with Movielens/models/SASRec'\n",
        "checkpoint = callbacks.ModelCheckpoint(model_filepath + '/checkpoint',\n",
        "                                       monitor = 'batch_top_10_categorical_accuracy',\n",
        "                                       save_best_only = True,\n",
        "                                       save_weights_only = True,\n",
        "                                       mode = 'max'\n",
        "                                       )\n",
        "earlyStopping = callbacks.EarlyStopping(patience = 5,\n",
        "                                        restore_best_weights = True,\n",
        "                                        monitor = 'val_batch_top_10_categorical_accuracy',\n",
        "                                        mode = 'max')\n",
        "csv_logger = callbacks.CSVLogger(model_filepath +'/training.log')"
      ],
      "metadata": {
        "id": "Bjeltv_a1prO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    prefetch_train,\n",
        "    validation_data = prefetch_val,\n",
        "    epochs = epoch,\n",
        "    verbose = 1,\n",
        "    callbacks = [checkpoint, earlyStopping, csv_logger],\n",
        "    validation_freq = 1\n",
        "    )"
      ],
      "metadata": {
        "id": "6VM9UH_4FT8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd55a1c3-14b8-481d-8965-fa397d12f866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4486/4486 [==============================] - 767s 168ms/step - batch_top_10_categorical_accuracy: 0.1260 - loss: 6.6450 - regularization_loss: 0.0000e+00 - total_loss: 6.6450 - val_batch_top_10_categorical_accuracy: 0.7215 - val_loss: 2.8223 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.8223\n",
            "Epoch 2/100\n",
            "4486/4486 [==============================] - 538s 119ms/step - batch_top_10_categorical_accuracy: 0.1611 - loss: 6.3573 - regularization_loss: 0.0000e+00 - total_loss: 6.3573 - val_batch_top_10_categorical_accuracy: 0.7314 - val_loss: 2.5156 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.5156\n",
            "Epoch 3/100\n",
            "4486/4486 [==============================] - 520s 115ms/step - batch_top_10_categorical_accuracy: 0.1699 - loss: 6.2949 - regularization_loss: 0.0000e+00 - total_loss: 6.2949 - val_batch_top_10_categorical_accuracy: 0.7344 - val_loss: 2.8754 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.8754\n",
            "Epoch 4/100\n",
            "4486/4486 [==============================] - 501s 111ms/step - batch_top_10_categorical_accuracy: 0.1747 - loss: 6.2614 - regularization_loss: 0.0000e+00 - total_loss: 6.2614 - val_batch_top_10_categorical_accuracy: 0.7378 - val_loss: 2.2770 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.2770\n",
            "Epoch 5/100\n",
            "4486/4486 [==============================] - 502s 111ms/step - batch_top_10_categorical_accuracy: 0.1778 - loss: 6.2395 - regularization_loss: 0.0000e+00 - total_loss: 6.2395 - val_batch_top_10_categorical_accuracy: 0.7398 - val_loss: 2.5474 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.5474\n",
            "Epoch 6/100\n",
            "4486/4486 [==============================] - 495s 110ms/step - batch_top_10_categorical_accuracy: 0.1801 - loss: 6.2235 - regularization_loss: 0.0000e+00 - total_loss: 6.2235 - val_batch_top_10_categorical_accuracy: 0.7406 - val_loss: 2.9538 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.9538\n",
            "Epoch 7/100\n",
            "4486/4486 [==============================] - 523s 115ms/step - batch_top_10_categorical_accuracy: 0.1819 - loss: 6.2109 - regularization_loss: 0.0000e+00 - total_loss: 6.2109 - val_batch_top_10_categorical_accuracy: 0.7423 - val_loss: 2.7766 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.7766\n",
            "Epoch 8/100\n",
            "4486/4486 [==============================] - 492s 109ms/step - batch_top_10_categorical_accuracy: 0.1834 - loss: 6.2004 - regularization_loss: 0.0000e+00 - total_loss: 6.2004 - val_batch_top_10_categorical_accuracy: 0.7441 - val_loss: 2.2987 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.2987\n",
            "Epoch 9/100\n",
            "4486/4486 [==============================] - 490s 108ms/step - batch_top_10_categorical_accuracy: 0.1846 - loss: 6.1914 - regularization_loss: 0.0000e+00 - total_loss: 6.1914 - val_batch_top_10_categorical_accuracy: 0.7453 - val_loss: 2.4565 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.4565\n",
            "Epoch 10/100\n",
            "4486/4486 [==============================] - 482s 107ms/step - batch_top_10_categorical_accuracy: 0.1857 - loss: 6.1836 - regularization_loss: 0.0000e+00 - total_loss: 6.1836 - val_batch_top_10_categorical_accuracy: 0.7447 - val_loss: 2.2922 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.2922\n",
            "Epoch 11/100\n",
            "4486/4486 [==============================] - 488s 108ms/step - batch_top_10_categorical_accuracy: 0.1867 - loss: 6.1770 - regularization_loss: 0.0000e+00 - total_loss: 6.1770 - val_batch_top_10_categorical_accuracy: 0.7459 - val_loss: 2.6502 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.6502\n",
            "Epoch 12/100\n",
            "4486/4486 [==============================] - 487s 108ms/step - batch_top_10_categorical_accuracy: 0.1875 - loss: 6.1712 - regularization_loss: 0.0000e+00 - total_loss: 6.1712 - val_batch_top_10_categorical_accuracy: 0.7451 - val_loss: 2.4942 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.4942\n",
            "Epoch 13/100\n",
            "4486/4486 [==============================] - 487s 108ms/step - batch_top_10_categorical_accuracy: 0.1882 - loss: 6.1659 - regularization_loss: 0.0000e+00 - total_loss: 6.1659 - val_batch_top_10_categorical_accuracy: 0.7453 - val_loss: 2.7740 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.7740\n",
            "Epoch 14/100\n",
            "4486/4486 [==============================] - 496s 110ms/step - batch_top_10_categorical_accuracy: 0.1888 - loss: 6.1612 - regularization_loss: 0.0000e+00 - total_loss: 6.1612 - val_batch_top_10_categorical_accuracy: 0.7464 - val_loss: 2.6756 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.6756\n",
            "Epoch 15/100\n",
            "4486/4486 [==============================] - 492s 109ms/step - batch_top_10_categorical_accuracy: 0.1894 - loss: 6.1571 - regularization_loss: 0.0000e+00 - total_loss: 6.1571 - val_batch_top_10_categorical_accuracy: 0.7467 - val_loss: 2.3592 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.3592\n",
            "Epoch 16/100\n",
            "4486/4486 [==============================] - 493s 109ms/step - batch_top_10_categorical_accuracy: 0.1899 - loss: 6.1532 - regularization_loss: 0.0000e+00 - total_loss: 6.1532 - val_batch_top_10_categorical_accuracy: 0.7474 - val_loss: 2.2916 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.2916\n",
            "Epoch 17/100\n",
            "4486/4486 [==============================] - 495s 109ms/step - batch_top_10_categorical_accuracy: 0.1904 - loss: 6.1498 - regularization_loss: 0.0000e+00 - total_loss: 6.1498 - val_batch_top_10_categorical_accuracy: 0.7476 - val_loss: 2.3298 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.3298\n",
            "Epoch 18/100\n",
            "4486/4486 [==============================] - 495s 109ms/step - batch_top_10_categorical_accuracy: 0.1908 - loss: 6.1467 - regularization_loss: 0.0000e+00 - total_loss: 6.1467 - val_batch_top_10_categorical_accuracy: 0.7472 - val_loss: 2.6286 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.6286\n",
            "Epoch 19/100\n",
            "4486/4486 [==============================] - 504s 112ms/step - batch_top_10_categorical_accuracy: 0.1912 - loss: 6.1436 - regularization_loss: 0.0000e+00 - total_loss: 6.1436 - val_batch_top_10_categorical_accuracy: 0.7481 - val_loss: 2.3106 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.3106\n",
            "Epoch 20/100\n",
            "4486/4486 [==============================] - 525s 116ms/step - batch_top_10_categorical_accuracy: 0.1917 - loss: 6.1409 - regularization_loss: 0.0000e+00 - total_loss: 6.1409 - val_batch_top_10_categorical_accuracy: 0.7477 - val_loss: 2.5883 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.5883\n",
            "Epoch 21/100\n",
            "4486/4486 [==============================] - 495s 110ms/step - batch_top_10_categorical_accuracy: 0.1920 - loss: 6.1382 - regularization_loss: 0.0000e+00 - total_loss: 6.1382 - val_batch_top_10_categorical_accuracy: 0.7479 - val_loss: 2.4936 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.4936\n",
            "Epoch 22/100\n",
            "4486/4486 [==============================] - 490s 109ms/step - batch_top_10_categorical_accuracy: 0.1924 - loss: 6.1358 - regularization_loss: 0.0000e+00 - total_loss: 6.1358 - val_batch_top_10_categorical_accuracy: 0.7496 - val_loss: 2.4612 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.4612\n",
            "Epoch 23/100\n",
            "4486/4486 [==============================] - 549s 122ms/step - batch_top_10_categorical_accuracy: 0.1927 - loss: 6.1333 - regularization_loss: 0.0000e+00 - total_loss: 6.1333 - val_batch_top_10_categorical_accuracy: 0.7494 - val_loss: 2.5213 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.5213\n",
            "Epoch 24/100\n",
            "4486/4486 [==============================] - 500s 111ms/step - batch_top_10_categorical_accuracy: 0.1930 - loss: 6.1312 - regularization_loss: 0.0000e+00 - total_loss: 6.1312 - val_batch_top_10_categorical_accuracy: 0.7476 - val_loss: 2.2642 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.2642\n",
            "Epoch 25/100\n",
            "4486/4486 [==============================] - 500s 111ms/step - batch_top_10_categorical_accuracy: 0.1933 - loss: 6.1291 - regularization_loss: 0.0000e+00 - total_loss: 6.1291 - val_batch_top_10_categorical_accuracy: 0.7501 - val_loss: 2.6549 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.6549\n",
            "Epoch 26/100\n",
            "4486/4486 [==============================] - 501s 111ms/step - batch_top_10_categorical_accuracy: 0.1936 - loss: 6.1272 - regularization_loss: 0.0000e+00 - total_loss: 6.1272 - val_batch_top_10_categorical_accuracy: 0.7487 - val_loss: 2.6245 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.6245\n",
            "Epoch 27/100\n",
            "4486/4486 [==============================] - 501s 111ms/step - batch_top_10_categorical_accuracy: 0.1939 - loss: 6.1252 - regularization_loss: 0.0000e+00 - total_loss: 6.1252 - val_batch_top_10_categorical_accuracy: 0.7494 - val_loss: 2.6151 - val_regularization_loss: 0.0000e+00 - val_total_loss: 2.6151\n",
            "Epoch 28/100\n",
            "3777/4486 [========================>.....] - ETA: 1:17 - batch_top_10_categorical_accuracy: 0.1939 - loss: 6.1253 - regularization_loss: 0.0000e+00 - total_loss: 6.1253"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(filepath = model_filepath + '/model_weight', save_format = 'tf')"
      ],
      "metadata": {
        "id": "03DIsFE4324s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(model_filepath + '/checkpoint')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RqhqY0cjoxm",
        "outputId": "30c5d1d0-bebb-4f24-998f-4df3fcddc048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7ff5d9b2bb20>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can evaluate our model on the test set:"
      ],
      "metadata": {
        "id": "jdf5XbM52h7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataset, return_dict=True)"
      ],
      "metadata": {
        "id": "3luxtcQ4jMjV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ade64520-0337-441c-b7cc-5c9b96403c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1371/1371 [==============================] - 46s 32ms/step - batch_top_10_categorical_accuracy: 0.7191 - loss: 2.9101 - regularization_loss: 0.0000e+00 - total_loss: 2.9101\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_top_10_categorical_accuracy': 0.719079315662384,\n",
              " 'loss': 2.660205602645874,\n",
              " 'regularization_loss': 0,\n",
              " 'total_loss': 2.660205602645874}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SDvkGPlbia3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yo0QgtmihqyJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}